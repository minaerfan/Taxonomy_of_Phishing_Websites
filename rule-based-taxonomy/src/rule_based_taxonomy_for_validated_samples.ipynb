{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc09e66d84e6cbb6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def select_ids(main, verified):\n",
    "    df3 = main[main['id'].isin(verified)]\n",
    "    return df3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a9f4d7c068b2f67"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def domain_age_lessThanOne(create_date, update_date):\n",
    "    if create_date != \"\" and create_date != \"expired\" and not pd.isna(create_date):\n",
    "        age = datetime.strptime(\"2024-04-23\", '%Y-%m-%d') - datetime.strptime(create_date[:10],\n",
    "                                                                              '%Y-%m-%d')\n",
    "        return (age.days // 365) < 1\n",
    "\n",
    "    elif create_date == \"\" and update_date != \"\":\n",
    "        age = datetime.strptime(\"2024-04-23\", '%Y-%m-%d') - datetime.strptime(update_date[:10],\n",
    "                                                                              '%Y-%m-%d')\n",
    "        if age.days < 365:\n",
    "            return None\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    elif create_date == \"expired\":\n",
    "        return True\n",
    "\n",
    "    return None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "902d20317e557fea"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def weighted_selection_without_subdomain(item):\n",
    "    # Calculate the number of hypotheses satisfied for each classification\n",
    "    new_domain = domain_age_lessThanOne(item['creation_date'], item['updated_date'])\n",
    "    shared_hosting_count = (\n",
    "                                   (0.5 if new_domain is None else 0 if new_domain else 1) +\n",
    "                                   (item['domain_indexed']) +\n",
    "                                   (item['is_archived']) +\n",
    "                                   (item['between_archives_similarity'] == -2) +\n",
    "                                   (item['phish_archives_similarity'] == -2)\n",
    "                           ) / 5\n",
    "\n",
    "    attacker_domain_count = (\n",
    "                                    (0.5 if new_domain is None else 1 if new_domain else 0) +\n",
    "                                    (not item['domain_indexed']) +\n",
    "                                    (not item['is_archived'] or item['phish_archives_similarity'] == 1\n",
    "                                     or item['phish_archives_similarity'] == 2 or item[\n",
    "                                         'phish_archives_similarity'] == 0)\n",
    "                            ) / 3\n",
    "\n",
    "    compromised_host_count = (\n",
    "                                     (0.5 if new_domain is None else 0 if new_domain else 1) +\n",
    "                                     (item['domain_indexed']) +\n",
    "                                     (item['is_archived']) +\n",
    "                                     (item['between_archives_similarity'] == 2) +\n",
    "                                     (item['phish_archives_similarity'] == -2)\n",
    "                             ) / 5\n",
    "\n",
    "    # Determine the classification based on the highest count\n",
    "    if shared_hosting_count >= max(compromised_host_count, attacker_domain_count):\n",
    "        shared_domain.append(item['domain'])\n",
    "        return 'shared_domain'\n",
    "    elif compromised_host_count >= attacker_domain_count:\n",
    "        compromised_domain.append(item['domain'])\n",
    "        return 'compromised_domain'\n",
    "    else:\n",
    "        attackers_domain.append(item['domain'])\n",
    "        return 'attackers_domain'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5280cea84d69740a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def weighted_selection_with_subdomain(item):\n",
    "    # Calculate the number of hypotheses satisfied for each classification\n",
    "    new_domain = domain_age_lessThanOne(item['creation_date'], item['updated_date'])\n",
    "    shared_hosting_count = (\n",
    "                                   (0.5 if new_domain is None else 0 if new_domain else 1) +\n",
    "                                   (item['domain_indexed']) +\n",
    "                                   (item['is_archived']) +\n",
    "                                   (item['between_archives_similarity'] == -2) +\n",
    "                                   (item['phish_archives_similarity'] == -2) +\n",
    "                                   (not item['control_over_dns']) +\n",
    "                                   (0.5 if pd.isna(item['control_over_ssl']) else 0 if item['control_over_ssl'] else 1)\n",
    "                           ) / 5\n",
    "\n",
    "    attacker_domain_count = (\n",
    "                                    (0.5 if new_domain is None else 1 if new_domain else 0) +\n",
    "                                    (not item['domain_indexed']) +\n",
    "                                    (not item['is_archived'] or item['phish_archives_similarity'] == 1\n",
    "                                     or item['phish_archives_similarity'] == 2 or item[\n",
    "                                         'phish_archives_similarity'] == 0)\n",
    "                            ) / 3\n",
    "\n",
    "    compromised_host_count = (\n",
    "                                     (0.5 if new_domain is None else 0 if new_domain else 1) +\n",
    "                                     (item['domain_indexed']) +\n",
    "                                     (item['is_archived']) +\n",
    "                                     (item['between_archives_similarity'] == 2) +\n",
    "                                     (item['phish_archives_similarity'] == -2)\n",
    "                             ) / 5\n",
    "\n",
    "\n",
    "    # Determine the classification based on the highest count\n",
    "    if shared_hosting_count >= max(compromised_host_count, attacker_domain_count):\n",
    "        shared_domain.append(item['domain'])\n",
    "        return 'shared_domain'\n",
    "    elif compromised_host_count >= attacker_domain_count:\n",
    "        compromised_domain.append(item['domain'])\n",
    "        return 'compromised_domain'\n",
    "    else:\n",
    "        attackers_domain.append(item['domain'])\n",
    "        return 'attackers_domain'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2865aebb1e84118"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def taxonomy_analysis(data):\n",
    "    for index, sample in data.iterrows():\n",
    "        if sample['known_hosting']:  # sample hosted on a shared platform\n",
    "            shared_domain.append(sample['domain'])\n",
    "            data.loc[index, 'taxonomy_predicted_category'] = 'shared_domain'\n",
    "        else:\n",
    "            if not sample['is_subdomain']:# sample is not a subdomain\n",
    "                if sample['is_on_root']:\n",
    "                    data.loc[index, 'taxonomy_predicted_category'] = 'attackers_domain'\n",
    "                    attackers_domain.append(sample['domain'])\n",
    "                else:\n",
    "                    data.loc[index, 'taxonomy_predicted_category'] = weighted_selection_without_subdomain(sample)\n",
    "\n",
    "            else:  # sample is a subdomain\n",
    "                data.loc[index, 'taxonomy_predicted_category'] = weighted_selection_with_subdomain(sample)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "170321b392186a66"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "path_prefix = '../data/'\n",
    "df = pd.read_csv(path_prefix + 'validated_dataset_for_taxonomy.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc36cc3a4f38d90"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "no_domain = []\n",
    "shared_domain = []\n",
    "attackers_domain = []\n",
    "compromised_domain = []\n",
    "df['taxonomy_predicted_category'] = None\n",
    "\n",
    "taxonomy_analysis(df)\n",
    "df.to_csv(path_prefix + 'taxonomy_results_for_validated_dataset.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e66dfc982ec41543"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
